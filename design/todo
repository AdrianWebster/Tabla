Projector Transform
- Load Projector coords (world space, pixel space)
- Draw into that transform
	- Add this to the pipeline, so we can toggle to it.
		- Maybe add another world-space pipeline frame so we can see things rendered in the 70x70 world...
			(so image space = world space)
	- Try loading that transformation matrix directly, so we let opengl handle the perspective transform for us
		- Backup: use an fbo, draw in world space pixels, then draw in framebuffer transformed (lame)
- How to set those coords?
	- First pass: eyeball it and enter something manually
	- If we are rendering projector output (16:9, 1024 x 768 or whatever it is--which might need to be hard coded--OH NO--we can detect it on startup when we choose the full-screen device we will draw to) then
		We will have an image space whose coordinates are in projector space.
		SO: We can put up a UI in that pipeline stage, four points for us to manipulate.
		Or even more simply, like before, mouse cursor will just show us the points and we can enter them.
		EXCEPT we have no idea where they are, so a GUI will be nice.
		Especially if we can fullscreen it and do it--and optically align it in the world/see the mouse cursor in the world.


Camera transform
√ Need to perspective transform image without losing pixels
√ Decouple world coordinates from pixel coordinates
	- Add more metadata to pipeline
		- every stage has world coordinates, by default set to image (if first), or prior stage
		- so every stage except first will be the same, the world coordinates of clipped subregion
		- first stage will be bigger than the table world. i think the mapping should be straightforward:
			output_world_bound_rect_pts :mapped-through: clip_output_rect -> clip_input_rect
			(or stuff will draw in it wrong)
	- Draw output in world space
		- Draw pipeline textures in world space
			Ortho Transform is for pipeline image's world coordinates
			Then draw the image in world coordinates
		- Draw balls, contours in world space
	- Transform contour output points to world space
√ Draw UI text elements/etc in window space.
	So a second pass while drawing in window coordinate space for current and future UI elements.

Basic
√ XML parameter loading/saving
	- Settings > Debug, etc..
	- Screen/Camera >
		- Which to use
		- Mapping coordinates
			- From where in camera frame?
			- To where in projector frame?
			- Scaling: In world units, what does this map to? (let's think in terms of inches or mm)
		- Contour resolution thresholds
	- Behaviors
	- Implement as nested callbacks.
		- getfile( path, getxmldatalambda() ) .. so does hot-loading, etc...
		- getxmlsubtree( xml, path, xmlsubtreehandler() .. could then call this for parts of it
- Better data visualization.
	- Construct a pipeline, log images and data flow edges to it;
		+ contour data, too
		+ transformation functions
			- with parameters
		+ this could be output as text, automatically generated graph, or linked to a diagram
			- the parameters could become live ui elements
			- this could become an intermediate language for specifying pipelines, so read back in; turn the tables on it.

Simulation
- √ Better topology handling (boxes in boxes)
- √ Balls have velocity
- √ Proper ball-ball collisions
- √ Ball masses/relative sizes matter.
- √ Ball <> Ball collision position correction is now relative to masses.

New features
- Generalized calibration of camera and projector.
	- Hard coded
	- Dynamic auto-detect
- Recognize colorful marker objects (lego bricks, eg)
	- Let me remove keyboard controls
- Sound effects
	- Clacking balls; use ping-pong sounds from Dave.
- Visual effects
	√ Squash and stretch balls
		- Normalize ball squashing effect? Just always shove in a normal vector, and have a tick counter... (and if multiple collisions, then average them, don't use biggest.)
		√ Ball<>Ball collision squishing effect is relative to ball sizes/masses.
	- Environment mapping on chrome balls
- Paper velocity/transformation
	- Use OCV Optical flow?
	- Then apply force to balls on collision w paper edge
	- Translate/rotate/transform balls
- More out there:
	- Lift paper/depth = height field they roll off of.
	- Detect hand with kinect, put old vision image data under it so we effectively ignore the hand.
		(Maybe don't even project there).

Technical
- Draw circles with more polys
- Decouple drawing from pipeline a bit
	- Dont' be checking query stage all the time. Have one place where we pull values from
	the pipeline and set our various matrices up. (I think.)
- Pipeline is not just a trace;
	- Vision code can pull parameters from it.
	- These parameters can specify (in vision code or elsewhere, by name) UI and value ranges.
- Refactoring
	√ Ball <> contour simulation logic in its own independent class. (world simulation)
		- This leaves room for another "simulation", the gray-code auto-registration that would calibrate registrations
	- Camera-projector registration in its own class (simply the camera-projector-world mapping)
		- Camera coordinates
		- World coordinates
		- Projector coordinates
		- 1:1
	√ OCV pipeline and outputs in its own class (image -> semantic actionable world data)
	√ Shove stuff into xml (make all this stuff tunable)
		- Ball World simulation parameters
		- Vision pipeline settings
		- Registration
			- Camera/world/projector coordinates
			- Which camera, which projector to use (we are assuming last right now, it seems OK.)
		- Debug settings
	√ Hot-load xml
	- The App that holds and manages all this stuff
		- Can swap between 'modes': calibration vs simulation
		- Can save/load mappings, and undertake to create them
		- Can show us debug visualizations
- Better registration
	- Automatic video-projector calibration (gray coding, or variant).
	- Will let me swap out, improve physical gear.
√ Lower latency
	- Think we got this down: pick proper resolutions.
		- Just need to parameterize this for different installs and easy experimentation.
		- Also, maybe dip into OSX camera api and get the resolutions.
	- new capture method?
	- multi-threaded? (measure latencies first)
- Use a Kinect.
	- Probably lower latency
	- Has IR for cleaner paper detection
	- Depth for hand rejection
	- Can do balls rolling off paper with z-height


Bugs
- XML loader will explode if file doesn't exist.